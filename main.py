import ollama
import datetime
import sys

# ConfiguraciÃ³n Modelo 
MODEL = "qwen2.5:3b"
KEEP_ALIVE = -1
TEMPERATURE = 0.35 
MAX_TOKENS = 220
SYSTEM_PROMPT = """

"""

#Herramientas
def consultar_estado_pedido(numero_pedido: str) -> str:
    """Consulta el estado actual de un pedido por su nÃºmero"""
    estados = {
        "12345": "En trÃ¡nsito - entrega estimada maÃ±ana 10-12 am",
        "67890": "Entregado el 15/02/2026",
        "54321": "Procesando pago - pendiente confirmaciÃ³n",
        "99999": "Cancelado por falta de stock"
    }
    return estados.get(numero_pedido.strip(), "No encontramos ese nÃºmero de pedido. Â¿Puedes confirmÃ¡rmelo?")


def obtener_hora_actual() -> str:
    """Devuelve la hora actual en San JosÃ©, Costa Rica"""
    now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=-6)))
    return now.strftime("%I:%M %p del %d de %B de %Y")


available_tools = {
    "consultar_estado_pedido": consultar_estado_pedido,
    "obtener_hora_actual": obtener_hora_actual,
}

#Carga del Modelo
print("Cargando LIA")
ollama.generate(model=MODEL, prompt="", keep_alive=KEEP_ALIVE)
print("Modelo Cargado en Memoria!\n")

#ChatBot
messages = [{"role": "system", "content": SYSTEM_PROMPT}]

print("Chatbot de servicio al cliente iniciado.")
print("Escribe 'adiÃ³s' o 'salir' para terminar.\n")

while True:
    user_input = input("TÃº: ").strip()

    if user_input.lower() in ["salir", "adiÃ³s", "bye", "exit"]:
        print("\nÂ¡Gracias por contactarnos! Estamos para ayudarte cuando quieras. ðŸ˜Š")
        sys.exit(0)

    if not user_input:
        continue

    messages.append({"role": "user", "content": user_input})

    try:
        # Primera llamada al modelo
        response = ollama.chat(
            model=MODEL,
            messages=messages,
            tools=list(available_tools.values()),
            keep_alive=KEEP_ALIVE,
            options={
                "temperature": TEMPERATURE,
                "num_predict": MAX_TOKENS
            }
        )

        messages.append(response["message"])

        #Proceso de Tools
        if response["message"].get("tool_calls"):
            print(" (usando herramientas internas...)")
            tool_results_added = False

            for tool_call in response["message"]["tool_calls"]:
                func_name = tool_call["function"]["name"]
                args = tool_call["function"].get("arguments") or {}

                if func_name == "consultar_estado_pedido":
                    numero = str(args.get("numero_pedido", "")).strip()
                    if not numero or not numero.isdigit() or len(numero) < 4:
                        result = "Por favor, dime el nÃºmero exacto de tu pedido para poder consultarlo."
                        print(f" â†’ {func_name} â†’ Ignorado (nÃºmero invÃ¡lido)")
                    else:
                        result = available_tools[func_name](numero)
                        print(f" â†’ {func_name} â†’ {result}")
                        tool_results_added = True

                elif func_name == "obtener_hora_actual":
                    result = available_tools[func_name]()
                    print(f" â†’ {func_name} â†’ {result}")
                    tool_results_added = True
                else:
                    result = "Herramienta desconocida"
                    tool_results_added = True

                # Agregamos siempre el resultado de la tool al historial
                messages.append({
                    "role": "tool",
                    "tool_name": func_name,
                    "content": str(result)
                })

            # Solo hacemos segunda llamada si se ejecutÃ³ alguna tool vÃ¡lida
            if tool_results_added:
                final_response = ollama.chat(
                    model=MODEL,
                    messages=messages,
                    tools=list(available_tools.values()),
                    keep_alive=KEEP_ALIVE,
                    options={"temperature": TEMPERATURE, "num_predict": MAX_TOKENS}
                )
                reply = final_response["message"]["content"].strip()
                messages.append(final_response["message"])
            else:
                reply = response["message"]["content"].strip()

        else:
            # SSi no hay tools,responder directo
            reply = response["message"]["content"].strip()

        print("Asistente:", reply)

    except Exception as e:
        print(f"Error: {str(e)}")
        print("AsegÃºrate que Ollama  no esta corriendo,ejecute en consola Â´ollama serve`.")